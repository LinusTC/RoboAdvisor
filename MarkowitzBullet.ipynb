{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markowitz Efficient Frontier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import scipy.optimize\n",
    "\n",
    "from fetchData import fetch_raw_data_yf, get_matrices, getNasdaqStocks\n",
    "from MonteCarloRBA import MonteCarloRBA\n",
    "from portfolioFunction import maximize_sharpe, create_correlation_matrix\n",
    "from LearningRBA import find_best_asset_to_remove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all Nasdaq Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets= [\n",
    "    \"AAPL\",  # Apple Inc.\n",
    "    \"MSFT\",  # Microsoft Corporation\n",
    "    \"AMZN\",  # Amazon.com Inc.\n",
    "    \"GOOGL\", # Alphabet Inc. (Google) Class A\n",
    "    \"GOOG\",  # Alphabet Inc. (Google) Class C\n",
    "    \"META\",    # Meta Platforms Inc (formerly Facebook)\n",
    "    \"TSLA\",  # Tesla Inc\n",
    "    \"UA\", # Berkshire Hathaway Inc. Class B\n",
    "    \"JPM\",   # JPMorgan Chase & Co.\n",
    "    \"V\",     # Visa Inc.\n",
    "    \"JNJ\",   # Johnson & Johnson\n",
    "    \"WMT\",   # Walmart Inc.\n",
    "    \"PG\",    # Procter & Gamble Co.\n",
    "    \"UNH\",   # UnitedHealth Group Inc.\n",
    "    \"MA\",    # Mastercard Inc.\n",
    "    \"NVDA\",  # NVIDIA Corporation\n",
    "    \"HD\",    # Home Depot Inc.\n",
    "    \"BAC\",   # Bank of America Corp\n",
    "    \"DIS\",   # Walt Disney Co\n",
    "    \"PYPL\",  # PayPal Holdings\n",
    "    \"VZ\",    # Verizon Communications Inc.\n",
    "    \"ADBE\",  # Adobe Inc.\n",
    "    \"CMCSA\", # Comcast Corporation\n",
    "    \"NFLX\",  # Netflix Inc.\n",
    "    \"KO\",    # Coca-Cola Co\n",
    "    \"NKE\",   # NIKE Inc.\n",
    "    \"PFE\",   # Pfizer Inc.\n",
    "    \"MRK\",   # Merck & Co., Inc.\n",
    "    \"PEP\",   # PepsiCo, Inc.\n",
    "    \"T\",     # AT&T Inc.\n",
    "    \"ABT\",   # Abbott Laboratories\n",
    "    \"CRM\",   # Salesforce.com Inc.\n",
    "    \"ORCL\",  # Oracle Corporation\n",
    "    \"ABBV\",  # AbbVie Inc.\n",
    "    \"CSCO\",  # Cisco Systems, Inc.\n",
    "    \"INTC\",  # Intel Corporation\n",
    "    \"TMO\",   # Thermo Fisher Scientific Inc.\n",
    "    \"XOM\",   # Exxon Mobil Corporation\n",
    "    \"ACN\",   # Accenture plc\n",
    "    \"LLY\",   # Eli Lilly and Company\n",
    "    \"COST\",  # Costco Wholesale Corporation\n",
    "    \"MCD\",   # McDonald's Corp\n",
    "    \"DHR\",   # Danaher Corporation\n",
    "    \"MDT\",   # Medtronic plc\n",
    "    \"NEE\",   # NextEra Energy, Inc.\n",
    "    \"BMY\",   # Bristol-Myers Squibb Company\n",
    "    \"QCOM\",  # Qualcomm Inc\n",
    "    \"CVX\",   # Chevron Corporation\n",
    "    \"WFC\",   # Wells Fargo & Co\n",
    "    \"LMT\",    # Lockheed Martin Corporation\n",
    "    \"GS\",   # Goldman Sachs Group, Inc.\n",
    "    \"MS\",   # Morgan Stanley\n",
    "    \"IBM\",  # International Business Machines Corporation\n",
    "    \"GE\",   # General Electric Company\n",
    "    \"F\",    # Ford Motor Company\n",
    "    \"GM\",   # General Motors Company\n",
    "    \"UBER\", # Uber Technologies, Inc.\n",
    "    \"LYFT\", # Lyft, Inc.\n",
    "    \"SNAP\", # Snap Inc.\n",
    "    \"TWTR\", # Twitter, Inc.\n",
    "    \"SPOT\", # Spotify Technology S.A.\n",
    "    \"AMD\",  # Advanced Micro Devices, Inc.\n",
    "    \"TXN\",  # Texas Instruments Incorporated\n",
    "    \"BABA\", # Alibaba Group Holding Limited\n",
    "    \"SAP\",  # SAP SE\n",
    "    \"HON\",  # Honeywell International Inc.\n",
    "    \"BA\",   # Boeing Company\n",
    "    \"RTX\",  # Raytheon Technologies Corporation\n",
    "    \"CAT\",  # Caterpillar Inc.\n",
    "    \"DE\",   # Deere & Company\n",
    "    \"MMM\",  # 3M Company\n",
    "    \"DUK\",  # Duke Energy Corporation\n",
    "    \"SO\",   # Southern Company\n",
    "    \"EXC\",  # Exelon Corporation\n",
    "    \"NEE\",  # NextEra Energy, Inc.\n",
    "    \"AEP\",  # American Electric Power Company, Inc.\n",
    "    \"SRE\",  # Sempra Energy\n",
    "    \"ETN\",  # Eaton Corporation plc\n",
    "    \"EMR\",  # Emerson Electric Co.\n",
    "    \"SYY\",  # Sysco Corporation\n",
    "    \"KR\",   # Kroger Co.\n",
    "    \"GIS\",  # General Mills, Inc.\n",
    "    \"K\",    # Kellogg Company\n",
    "    \"CPB\",  # Campbell Soup Company\n",
    "    \"MO\",   # Altria Group, Inc.\n",
    "    \"PM\",   # Philip Morris International Inc.\n",
    "    \"BTI\",  # British American Tobacco plc\n",
    "    \"RDY\",  # Dr. Reddy's Laboratories Ltd.\n",
    "    \"GILD\", # Gilead Sciences, Inc.\n",
    "    \"BIIB\", # Biogen Inc.\n",
    "    \"CELG\", # Celgene Corporation\n",
    "    \"AMGN\", # Amgen Inc.\n",
    "    \"SYK\",  # Stryker Corporation\n",
    "    \"BSX\",  # Boston Scientific Corporation\n",
    "    \"ISRG\", # Intuitive Surgical, Inc.\n",
    "    \"ZBH\",  # Zimmer Biomet Holdings, Inc.\n",
    "    \"EW\",   # Edwards Lifesciences Corporation\n",
    "    \"RMD\",  # ResMed Inc.\n",
    "    \"VRTX\", # Vertex Pharmaceuticals Incorporated\n",
    "    \"REGN\",  # Regeneron Pharmaceuticals, Inc.\n",
    "]\n",
    "\n",
    "len(assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  99 of 99 completed\n",
      "\n",
      "99 Failed downloads:\n",
      "['TWTR', 'AAPL', 'VZ', 'CRM', 'MSFT', 'JNJ', 'BTI', 'JPM', 'ABBV', 'PG', 'MMM', 'WFC', 'KO', 'NEE', 'UBER', 'DHR', 'EXC', 'NVDA', 'RTX', 'COST', 'AMD', 'PEP', 'AMGN', 'ZBH', 'CAT', 'REGN', 'CELG', 'NKE', 'EMR', 'UNH', 'F', 'BABA', 'LMT', 'K', 'SPOT', 'GM', 'CPB', 'WMT', 'ACN', 'BIIB', 'SYK', 'AMZN', 'BAC', 'MS', 'ORCL', 'NFLX', 'IBM', 'DUK', 'SAP', 'BSX', 'LYFT', 'HON', 'SNAP', 'DE', 'HD', 'GS', 'T', 'RDY', 'CSCO', 'SYY', 'TXN', 'BA', 'CMCSA', 'PFE', 'GOOG', 'PM', 'MCD', 'PYPL', 'CVX', 'BMY', 'RMD', 'XOM', 'GILD', 'QCOM', 'TSLA', 'EW', 'GE', 'ETN', 'MRK', 'KR', 'LLY', 'MA', 'SO', 'UA', 'INTC', 'META', 'GOOGL', 'ISRG', 'SRE', 'MO', 'AEP', 'ADBE', 'DIS', 'TMO', 'MDT', 'ABT', 'GIS', 'VRTX', 'V']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No data fetched for any assets.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m raw_data, asset_errors, max_combination\u001b[38;5;241m=\u001b[39m \u001b[43mfetch_raw_data_yf\u001b[49m\u001b[43m(\u001b[49m\u001b[43massets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programming Projects\\School\\Year 4\\RoboAdvisor\\fetchData.py:34\u001b[0m, in \u001b[0;36mfetch_raw_data_yf\u001b[1;34m(asset_basket)\u001b[0m\n\u001b[0;32m     31\u001b[0m         asset_errors\u001b[38;5;241m.\u001b[39mappend(asset)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data fetched for any assets.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     37\u001b[0m max_combination \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(unique_assets) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(asset_errors)\n",
      "\u001b[1;31mValueError\u001b[0m: No data fetched for any assets."
     ]
    }
   ],
   "source": [
    "raw_data, asset_errors, max_combination= fetch_raw_data_yf(assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mean, Volatility and Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, cov, annualized_returns = get_matrices(raw_data, max_combination, None)[0]\n",
    "correlation_matrix = create_correlation_matrix(cov)\n",
    "volatility = np.sqrt(np.diag(cov))\n",
    "\n",
    "risk_free_rate=0 \n",
    "sharpe_ratios = (annualized_returns - risk_free_rate) / volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hover_texts = [\n",
    "    f\"{ticker} <br>Volatility: {vol:.2f} <br>Returns: {ret:.2%} <br>Sharpe Ratio: {sr:.2f}\"\n",
    "    for ticker, vol, ret, sr in zip(names, volatility, annualized_returns, sharpe_ratios)\n",
    "]\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(\n",
    "    x=volatility, \n",
    "    y=annualized_returns, \n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    hovertext=hover_texts,\n",
    "    marker=dict(color=sharpe_ratios, colorscale = 'RdBu', size=6, line=dict(width=1), colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Markowitz Mean Varience Model',\n",
    "    xaxis_title='Volatility (Standard Deviation)',\n",
    "    yaxis_title='Annualized Returns',\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Monte Carlo Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_portfolios, dominant_portfolios = MonteCarloRBA(names, cov, annualized_returns, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(dominant_portfolios) ,len(all_portfolios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = go.Figure()\n",
    "\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=[p[\"variance\"]**0.5 for p in all_portfolios],\n",
    "    y=[p[\"return\"] for p in all_portfolios],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[p[\"return\"] / (p[\"variance\"]**0.5) for p in all_portfolios],\n",
    "        showscale=True,\n",
    "        size=7,\n",
    "        line=dict(width=1),\n",
    "        colorscale=\"RdBu\",\n",
    "        colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "    ),\n",
    "    hoverinfo='text',\n",
    "    text=[\n",
    "        f\"Return: {p['return']:.2%}<br>Volatility: {p['variance']**0.5:.2f}<br>\" +\n",
    "        f\"Sharpe Ratio: {p['return'] / (p['variance']**0.5):.2f}<br>\" +\n",
    "        \"<br>\".join([f\"{p['tickers'][i]}: Weight={p['weights'][i]:.2f}\" for i in range(len(p['tickers']))])\n",
    "        for p in all_portfolios\n",
    "    ]\n",
    "))\n",
    "\n",
    "fig1.update_layout(\n",
    "    xaxis=dict(title='Volatility (Standard Deviation)'),\n",
    "    yaxis=dict(title='Annualised Returns'),\n",
    "    title='Sample of Random Portfolios'\n",
    ")\n",
    "\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = go.Figure()\n",
    "\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=[p[\"variance\"]**0.5 for p in dominant_portfolios],  # Convert variance to volatility\n",
    "    y=[p[\"return\"] for p in dominant_portfolios],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[p[\"return\"] / (p[\"variance\"]**0.5) for p in dominant_portfolios],  # Sharpe Ratio\n",
    "        showscale=True,\n",
    "        size=7,\n",
    "        line=dict(width=1),\n",
    "        colorscale=\"RdBu\",\n",
    "        colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "    ),\n",
    "    hoverinfo='text',\n",
    "    text=[\n",
    "        f\"Return: {p['return']:.2%}<br>Volatility: {p['variance']**0.5:.2f}<br>\" +\n",
    "        f\"Sharpe Ratio: {p['return'] / (p['variance']**0.5):.2f}<br>\" +\n",
    "        \"<br>\".join([f\"{p['tickers'][i]}: Weight={p['weights'][i]:.2f}\" for i in range(len(p['tickers']))])\n",
    "        for p in dominant_portfolios\n",
    "    ],\n",
    "    name=\"Portfolios\"\n",
    "))\n",
    "\n",
    "\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=volatility, \n",
    "    y=annualized_returns,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    hovertext=[\n",
    "        f\"{name} <br>Volatility: {vol:.2f} <br>Returns: {ret:.2%} <br>Sharpe Ratio: {sr:.2f}\"\n",
    "        for name, vol, ret, sr in zip(names, volatility, annualized_returns, sharpe_ratios)\n",
    "    ],\n",
    "    marker=dict(\n",
    "        color='brown',\n",
    "        size=5,\n",
    "        symbol='triangle-up',  # Sets the marker shape to a triangle\n",
    "        line=dict(width=1)\n",
    "    ),\n",
    "    name=\"Individual Assets\"\n",
    "))\n",
    "\n",
    "fig2.update_layout(\n",
    "    title='Sample of Random Portfolios',\n",
    "    xaxis_title='Volatility (Standard Deviation)',\n",
    "    yaxis_title='Annualized Return',\n",
    "    legend=dict(y=5\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 ML Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLRBA(ticker, covariances, returns, num_iterations=10000, risk_free_rate = 0):\n",
    "    num_assets = 5\n",
    "    base_portfolio = np.random.choice(list(ticker), num_assets, replace=False)\n",
    "    highest_sharpe = -np.inf\n",
    "\n",
    "    all_portfolios = []\n",
    "\n",
    "    tested_assets = set()\n",
    "\n",
    "    def _get_portfolio_stats (portfolio_assets, risk_free_rate = 0):\n",
    "        p_asset_ret = returns.loc[portfolio_assets].values\n",
    "        p_asset_var = covariances.loc[portfolio_assets, portfolio_assets].values\n",
    "        best_p_weights = maximize_sharpe(p_asset_ret, p_asset_var)\n",
    "        p_ret = np.dot(best_p_weights,p_asset_ret)\n",
    "        p_var = np.dot(best_p_weights, p_asset_var @ best_p_weights)\n",
    "        sharpe = (p_ret - risk_free_rate) / np.sqrt(p_var)\n",
    "\n",
    "        return p_asset_ret, p_asset_var, sharpe, p_ret, p_var, best_p_weights\n",
    "    \n",
    "    def _update_portfolios_array(portfolios, assets, weights, p_ret, p_var):\n",
    "        portfolios.append({\n",
    "            \"tickers\": assets,\n",
    "            \"weights\": weights,\n",
    "            \"return\": p_ret,\n",
    "            \"variance\": p_var,\n",
    "            \"sharpe\": (p_ret-risk_free_rate)/np.sqrt(p_var),\n",
    "        })\n",
    "    \n",
    "    curr_ret, curr_var, curr_sharpe, curr_p_return, curr_p_variance, curr_p_weights = _get_portfolio_stats(base_portfolio, risk_free_rate)\n",
    "    _update_portfolios_array(all_portfolios, base_portfolio, curr_p_weights, curr_p_return, curr_p_variance)\n",
    "\n",
    "    good_portfolios = all_portfolios.copy()\n",
    "    best_portfolio = base_portfolio.copy()\n",
    "\n",
    "    highest_sharpe = curr_sharpe\n",
    "    for _ in tqdm(range(num_iterations)):\n",
    "        asset_to_remove = find_best_asset_to_remove(best_portfolio, curr_var, curr_ret, return_weight=0.5, corr_weight=0.5)     #most_correlated_asset, _, _ = find_correlation_matrix(portfolio, curr_variances)\n",
    "        new_portfolio = [str(asset) for asset in best_portfolio if asset != asset_to_remove]\n",
    "\n",
    "        ranked_assets = find_asset_to_add(new_portfolio, ticker, covariances, returns)         # Find the next best asset to add to the portfolio\n",
    "        asset_to_add = ranked_assets.index[0]\n",
    "\n",
    "        for asset in ranked_assets.index:\n",
    "            if asset not in tested_assets:\n",
    "                asset_to_add = asset\n",
    "                break\n",
    "        \n",
    "        new_portfolio.append(asset_to_add)\n",
    "        tested_assets.add(asset_to_add)\n",
    "\n",
    "        # Substitute in and measure portfolio performance based on sharpe ratio\n",
    "        new_returns, new_var, new_sharpe_ratio, new_p_return, new_p_variance, new_p_weights = _get_portfolio_stats(new_portfolio, risk_free_rate)\n",
    "\n",
    "        _update_portfolios_array(all_portfolios, new_portfolio, new_p_weights, new_p_return, new_p_variance)\n",
    "        \n",
    "        if new_sharpe_ratio > highest_sharpe:\n",
    "            highest_sharpe = new_sharpe_ratio\n",
    "            best_portfolio = new_portfolio\n",
    "            curr_ret, curr_var = new_returns, new_var\n",
    "\n",
    "            _update_portfolios_array(good_portfolios, new_portfolio, new_p_weights, new_p_return, new_p_variance)\n",
    "\n",
    "            tested_assets.clear()\n",
    "\n",
    "        # If Sharpe ratio was worse, then move on to the next least correlated asset\n",
    "        # If Sharpe ratio is better, set as new base portfolio, and repeat the process for num_iterations times\n",
    "        # Adjust the sharpe ratio, maybe more emphasis on returns/volatility\n",
    "        # Update weights to value return or corr\n",
    "        # See how many iterations it takes to get here, whats a good threshold/stopping point\n",
    "        # Backtesting\n",
    "        # Train a model to maybe predict the sharpe ratio of a portfolio\n",
    "\n",
    "    base_details = good_portfolios[0]\n",
    "    best_details = good_portfolios[len(good_portfolios)-1]\n",
    "\n",
    "    return base_details, best_details, good_portfolios, all_portfolios\n",
    "\n",
    "def find_asset_to_add(portfolio_assets, all_assets, all_covariance, all_returns, return_weight=0.5, corr_weight=0.5):\n",
    "    remaining_assets = [asset for asset in all_assets if asset not in portfolio_assets]\n",
    "    \n",
    "    corr_matrix = create_correlation_matrix(all_covariance)\n",
    "    avg_corrs = corr_matrix.loc[remaining_assets, portfolio_assets].mean(axis=1)\n",
    "    \n",
    "    norm_corr = (avg_corrs - avg_corrs.min()) / (avg_corrs.max() - avg_corrs.min())\n",
    "    norm_returns = (all_returns.loc[remaining_assets] - all_returns.min()) / (all_returns.max() - all_returns.min())\n",
    "\n",
    "    combined_score = corr_weight * norm_corr + return_weight * norm_returns\n",
    "    \n",
    "    ranked_assets = combined_score.sort_values(ascending=False)\n",
    "    \n",
    "    return ranked_assets\n",
    "\n",
    "base_portfolio, best_portfolio, good_portfolios, all_portfolios = MLRBA(names, cov, annualized_returns, 300)\n",
    "base_portfolio, best_portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[p[\"variance\"]**0.5 for p in all_portfolios],  # Convert variance to volatility\n",
    "    y=[p[\"return\"] for p in all_portfolios],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[p[\"sharpe\"] for p in all_portfolios],  # Sharpe Ratio\n",
    "        showscale=True,\n",
    "        size=7,\n",
    "        line=dict(width=1),\n",
    "        colorscale=\"RdBu\",\n",
    "        colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "    ),\n",
    "    hoverinfo='text',\n",
    "    text=[\n",
    "        f\"Return: {p['return']:.2%}<br>Volatility: {p['variance']**0.5:.2f}<br>\" +\n",
    "        f\"Sharpe Ratio: {p['return'] / (p['variance']**0.5):.2f}<br>\" +\n",
    "        \"<br>\".join([f\"{p['tickers'][i]}: Weight={p['weights'][i]:.2f}\" for i in range(len(p['tickers']))])\n",
    "        for p in all_portfolios\n",
    "    ],\n",
    "    name=\"Portfolios\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sample of Random Portfolios',\n",
    "    xaxis_title='Volatility (Standard Deviation)',\n",
    "    yaxis_title='Annualized Return',\n",
    "    legend=dict(y=5\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_ratios = [portfolio['sharpe'] for portfolio in all_portfolios]\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=list(range(len(sharpe_ratios))), y=sharpe_ratios, mode='lines+markers'))\n",
    "fig.update_layout(title='Sharpe Ratio Over Iterations',\n",
    "                  xaxis_title='Iteration',\n",
    "                  yaxis_title='Sharpe Ratio',\n",
    "                  )\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roboA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
