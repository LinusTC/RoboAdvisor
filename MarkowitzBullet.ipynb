{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bj91ThpmabDR"
   },
   "source": [
    "# Investment Robo-advisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w31yow0TabDS"
   },
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:45:53.383324Z",
     "iopub.status.busy": "2025-03-28T01:45:53.382444Z",
     "iopub.status.idle": "2025-03-28T01:45:58.308586Z",
     "shell.execute_reply": "2025-03-28T01:45:58.307422Z",
     "shell.execute_reply.started": "2025-03-28T01:45:53.383271Z"
    },
    "id": "EvpNgOhEabDS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout # type: ignore\n",
    "\n",
    "from fetchData import fetch_raw_data_yf, getSNP500, fetch_raw_data_yf_all, getNasdaq_comp\n",
    "from LearningRBA import MLRBA_V1, MLRBA_V2\n",
    "from MonteCarloRBA import MonteCarloRBA\n",
    "from PortfolioFunction import maximize_sharpe, create_correlation_matrix, get_sharpe_ratio, get_matrices, maximize_sharpe_SLSQP\n",
    "from LearningRBA import find_best_asset_to_remove, find_asset_to_add\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnySmmT6abDT"
   },
   "source": [
    "## 2. Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bz1yuGUabDT"
   },
   "source": [
    "### Get all Nasdaq Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T01:45:58.310597Z",
     "iopub.status.busy": "2025-03-28T01:45:58.309866Z",
     "iopub.status.idle": "2025-03-28T01:45:58.610539Z",
     "shell.execute_reply": "2025-03-28T01:45:58.609457Z",
     "shell.execute_reply.started": "2025-03-28T01:45:58.310560Z"
    },
    "id": "H4G7yoJuabDT",
    "outputId": "e6e2de66-44f1-4d77-8bc1-bfe43fe6e4cd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "assets= [\n",
    "    \"AAPL\",  # Apple Inc.\n",
    "    \"MSFT\",  # Microsoft Corporation\n",
    "    \"AMZN\",  # Amazon.com Inc.\n",
    "    \"GOOGL\", # Alphabet Inc. (Google) Class A\n",
    "    \"GOOG\",  # Alphabet Inc. (Google) Class C\n",
    "    \"META\",    # Meta Platforms Inc (formerly Facebook)\n",
    "    \"TSLA\",  # Tesla Inc\n",
    "    \"UA\", # Berkshire Hathaway Inc. Class B\n",
    "    \"JPM\",   # JPMorgan Chase & Co.\n",
    "    \"V\",     # Visa Inc.\n",
    "    \"JNJ\",   # Johnson & Johnson\n",
    "    \"WMT\",   # Walmart Inc.\n",
    "    \"PG\",    # Procter & Gamble Co.\n",
    "    \"UNH\",   # UnitedHealth Group Inc.\n",
    "    \"MA\",    # Mastercard Inc.\n",
    "    \"NVDA\",  # NVIDIA Corporation\n",
    "    \"HD\",    # Home Depot Inc.\n",
    "    \"BAC\",   # Bank of America Corp\n",
    "    \"DIS\",   # Walt Disney Co\n",
    "    \"PYPL\",  # PayPal Holdings\n",
    "    \"VZ\",    # Verizon Communications Inc.\n",
    "    \"ADBE\",  # Adobe Inc.\n",
    "    \"CMCSA\", # Comcast Corporation\n",
    "    \"NFLX\",  # Netflix Inc.\n",
    "    \"KO\",    # Coca-Cola Co\n",
    "    \"NKE\",   # NIKE Inc.\n",
    "    \"PFE\",   # Pfizer Inc.\n",
    "    \"MRK\",   # Merck & Co., Inc.\n",
    "    \"PEP\",   # PepsiCo, Inc.\n",
    "    \"T\",     # AT&T Inc.\n",
    "    \"ABT\",   # Abbott Laboratories\n",
    "    \"CRM\",   # Salesforce.com Inc.\n",
    "    \"ORCL\",  # Oracle Corporation\n",
    "    \"ABBV\",  # AbbVie Inc.\n",
    "    \"CSCO\",  # Cisco Systems, Inc.\n",
    "    \"INTC\",  # Intel Corporation\n",
    "    \"TMO\",   # Thermo Fisher Scientific Inc.\n",
    "    \"XOM\",   # Exxon Mobil Corporation\n",
    "    \"ACN\",   # Accenture plc\n",
    "    \"LLY\",   # Eli Lilly and Company\n",
    "    \"COST\",  # Costco Wholesale Corporation\n",
    "    \"MCD\",   # McDonald's Corp\n",
    "    \"DHR\",   # Danaher Corporation\n",
    "    \"MDT\",   # Medtronic plc\n",
    "    \"NEE\",   # NextEra Energy, Inc.\n",
    "    \"BMY\",   # Bristol-Myers Squibb Company\n",
    "    \"QCOM\",  # Qualcomm Inc\n",
    "    \"CVX\",   # Chevron Corporation\n",
    "    \"WFC\",   # Wells Fargo & Co\n",
    "    \"LMT\",    # Lockheed Martin Corporation\n",
    "    \"GS\",   # Goldman Sachs Group, Inc.\n",
    "    \"MS\",   # Morgan Stanley\n",
    "    \"IBM\",  # International Business Machines Corporation\n",
    "    \"GE\",   # General Electric Company\n",
    "    \"F\",    # Ford Motor Company\n",
    "    \"GM\",   # General Motors Company\n",
    "    \"UBER\", # Uber Technologies, Inc.\n",
    "    \"LYFT\", # Lyft, Inc.\n",
    "    \"SNAP\", # Snap Inc.\n",
    "    \"TWTR\", # Twitter, Inc.\n",
    "    \"SPOT\", # Spotify Technology S.A.\n",
    "    \"AMD\",  # Advanced Micro Devices, Inc.\n",
    "    \"TXN\",  # Texas Instruments Incorporated\n",
    "    \"BABA\", # Alibaba Group Holding Limited\n",
    "    \"SAP\",  # SAP SE\n",
    "    \"HON\",  # Honeywell International Inc.\n",
    "    \"BA\",   # Boeing Company\n",
    "    \"RTX\",  # Raytheon Technologies Corporation\n",
    "    \"CAT\",  # Caterpillar Inc.\n",
    "    \"DE\",   # Deere & Company\n",
    "    \"MMM\",  # 3M Company\n",
    "    \"DUK\",  # Duke Energy Corporation\n",
    "    \"SO\",   # Southern Company\n",
    "    \"EXC\",  # Exelon Corporation\n",
    "    \"NEE\",  # NextEra Energy, Inc.\n",
    "    \"AEP\",  # American Electric Power Company, Inc.\n",
    "    \"SRE\",  # Sempra Energy\n",
    "    \"ETN\",  # Eaton Corporation plc\n",
    "    \"EMR\",  # Emerson Electric Co.\n",
    "    \"SYY\",  # Sysco Corporation\n",
    "    \"KR\",   # Kroger Co.\n",
    "    \"GIS\",  # General Mills, Inc.\n",
    "    \"K\",    # Kellogg Company\n",
    "    \"CPB\",  # Campbell Soup Company\n",
    "    \"MO\",   # Altria Group, Inc.\n",
    "    \"PM\",   # Philip Morris International Inc.\n",
    "    \"BTI\",  # British American Tobacco plc\n",
    "    \"RDY\",  # Dr. Reddy's Laboratories Ltd.\n",
    "    \"GILD\", # Gilead Sciences, Inc.\n",
    "    \"BIIB\", # Biogen Inc.\n",
    "    \"CELG\", # Celgene Corporation\n",
    "    \"AMGN\", # Amgen Inc.\n",
    "    \"SYK\",  # Stryker Corporation\n",
    "    \"BSX\",  # Boston Scientific Corporation\n",
    "    \"ISRG\", # Intuitive Surgical, Inc.\n",
    "    \"ZBH\",  # Zimmer Biomet Holdings, Inc.\n",
    "    \"EW\",   # Edwards Lifesciences Corporation\n",
    "    \"RMD\",  # ResMed Inc.\n",
    "    \"VRTX\", # Vertex Pharmaceuticals Incorporated\n",
    "    \"REGN\",  # Regeneron Pharmaceuticals, Inc.\n",
    "]\n",
    "\n",
    "assets = getSNP500()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T01:45:58.612180Z",
     "iopub.status.busy": "2025-03-28T01:45:58.611759Z",
     "iopub.status.idle": "2025-03-28T01:45:58.617112Z",
     "shell.execute_reply": "2025-03-28T01:45:58.615944Z",
     "shell.execute_reply.started": "2025-03-28T01:45:58.612143Z"
    },
    "id": "AvJfF_5YabDU",
    "outputId": "e2769ab4-6379-4ccc-e628-557b92733cd1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(\"2024-01-01\")\n",
    "end_date = pd.Timestamp(\"2025-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:45:58.618781Z",
     "iopub.status.busy": "2025-03-28T01:45:58.618327Z",
     "iopub.status.idle": "2025-03-28T01:48:06.972943Z",
     "shell.execute_reply": "2025-03-28T01:48:06.971777Z",
     "shell.execute_reply.started": "2025-03-28T01:45:58.618735Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "raw_data, asset_errors, max_combination= fetch_raw_data_yf(assets, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyXEENSbabDU"
   },
   "source": [
    "## 3. Mean, Volatility and Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T01:48:06.976659Z",
     "iopub.status.busy": "2025-03-28T01:48:06.976361Z",
     "iopub.status.idle": "2025-03-28T01:48:07.104927Z",
     "shell.execute_reply": "2025-03-28T01:48:07.103928Z",
     "shell.execute_reply.started": "2025-03-28T01:48:06.976634Z"
    },
    "id": "V8UnmVllabDU",
    "outputId": "5db2e605-2732-40fd-8052-5cddc38fded9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "names, annualized_returns, unweighted_annaulized_returns, weighted_returns_matrix, normal_returns_matrix, cov, correlation_matrix = get_matrices(raw_data)\n",
    "\n",
    "volatility = np.sqrt(np.diag(cov))\n",
    "risk_free_rate=0\n",
    "sharpe_ratios = (annualized_returns - risk_free_rate) / volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T01:48:07.107459Z",
     "iopub.status.busy": "2025-03-28T01:48:07.107065Z",
     "iopub.status.idle": "2025-03-28T01:48:07.660329Z",
     "shell.execute_reply": "2025-03-28T01:48:07.659148Z",
     "shell.execute_reply.started": "2025-03-28T01:48:07.107424Z"
    },
    "id": "70g4vm3qabDU",
    "outputId": "3974e87c-1b85-4392-e8b8-594c2626466e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hover_texts = [\n",
    "    f\"<br>Symbol: {ticker} <br>Volatility: {vol:.3f} <br>Returns: {ret:.3%} <br>Sharpe Ratio: {sr:.3f}\"\n",
    "    for ticker, vol, ret, sr in zip(names, volatility, annualized_returns, sharpe_ratios)\n",
    "]\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(\n",
    "    x=volatility,\n",
    "    y=annualized_returns,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    hovertext=hover_texts,\n",
    "    marker=dict(color=sharpe_ratios, colorscale = 'RdBu', size=6, line=dict(width=1), colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Annual Performance of Individual Assets',\n",
    "    xaxis_title='Volatility (Standard Deviation)',\n",
    "    yaxis_title='Annualized Returns',\n",
    "    width = 1920,\n",
    "    height = 1080,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "#fig.write_html(\"PerformanceofIndividualAssets.html\")\n",
    "#fig.write_image(\"PerformanceofIndividualAssets.png\", format='png', width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrating SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:48:07.662079Z",
     "iopub.status.busy": "2025-03-28T01:48:07.661649Z",
     "iopub.status.idle": "2025-03-28T01:48:07.680432Z",
     "shell.execute_reply": "2025-03-28T01:48:07.678989Z",
     "shell.execute_reply.started": "2025-03-28T01:48:07.662046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rand_assets = np.random.choice(list(names), 5, replace=False)\n",
    "\n",
    "selected_returns = annualized_returns.loc[rand_assets].values\n",
    "selected_covariances = cov.loc[rand_assets, rand_assets].values\n",
    "\n",
    "optimized_weights, weights_history, sharpe_history = maximize_sharpe_SLSQP(selected_returns, selected_covariances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:48:07.681837Z",
     "iopub.status.busy": "2025-03-28T01:48:07.681522Z",
     "iopub.status.idle": "2025-03-28T01:48:08.021178Z",
     "shell.execute_reply": "2025-03-28T01:48:08.020008Z",
     "shell.execute_reply.started": "2025-03-28T01:48:07.681789Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Portfolio Weights Over Iterations\", \"Sharpe Ratio Over Iterations\"))\n",
    "\n",
    "for i in range(len(selected_returns)):\n",
    "    fig.add_trace(go.Scatter(x=list(range(len(weights_history))), \n",
    "                             y=[h[i] for h in weights_history], \n",
    "                             mode='lines+markers', \n",
    "                             name=f'Asset {i+1} Weight'), \n",
    "                  row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(len(sharpe_history))), \n",
    "                         y=sharpe_history, \n",
    "                         mode='lines+markers', \n",
    "                         name='Sharpe Ratio'), \n",
    "              row=1, col=2)\n",
    "\n",
    "fig.update_layout(title_text='Portfolio Optimization Analysis',\n",
    "                  xaxis_title='Iteration',\n",
    "                  yaxis_title='Weight',\n",
    "                  legend_title='Assets',\n",
    "                    font=dict(\n",
    "                        family=\"Cambria\",\n",
    "                        size=18,\n",
    "                    )\n",
    ")\n",
    "\n",
    "# Update xaxis and yaxis properties for Sharpe Ratio subplot\n",
    "fig.update_xaxes(title_text=\"Iteration\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Sharpe Ratio\", row=1, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "#fig.write_html(\"SLSQPDemo.html\")\n",
    "#fig.write_image(\"SLSQPDemo.png\", format='png', width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3i7iFfDabDV"
   },
   "source": [
    "## 4.0 Monte Carlo Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T01:48:08.023073Z",
     "iopub.status.busy": "2025-03-28T01:48:08.022647Z",
     "iopub.status.idle": "2025-03-28T01:49:30.374046Z",
     "shell.execute_reply": "2025-03-28T01:49:30.372927Z",
     "shell.execute_reply.started": "2025-03-28T01:48:08.023041Z"
    },
    "id": "fsgRqCSWabDV",
    "outputId": "55346305-b21e-48aa-bd8b-0daed1a50060",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_portfolios, dominant_portfolios = MonteCarloRBA(names, cov, annualized_returns, 10000, min_assets=8, max_assets=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T01:49:30.375612Z",
     "iopub.status.busy": "2025-03-28T01:49:30.375258Z",
     "iopub.status.idle": "2025-03-28T01:49:30.404654Z",
     "shell.execute_reply": "2025-03-28T01:49:30.403338Z",
     "shell.execute_reply.started": "2025-03-28T01:49:30.375576Z"
    },
    "id": "09tYBpwxabDV",
    "outputId": "055bc292-d45d-4b5b-baaf-482d1c4ede81",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "iterations = [portfolio['iteration'] for portfolio in dominant_portfolios]\n",
    "counts = list(range(1, len(dominant_portfolios) + 1))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=iterations, y=counts,\n",
    "                        mode='lines',\n",
    "                        name='Dominant Portfolios',\n",
    "                        line=dict(shape='spline')\n",
    "))  \n",
    "\n",
    "fig.update_layout(\n",
    "    title='Growth of Dominant Portfolios Over Iterations',\n",
    "    xaxis_title='Portfolios Generated',\n",
    "    yaxis_title='Number of Dominant Portfolios Found',\n",
    "    height=1080,\n",
    "    width=1920,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "#fig.write_html(\"FrequencyOfDom.html\")\n",
    "#fig.write_image(\"FrequencyOfDom.png\", format='png', width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T01:49:30.406236Z",
     "iopub.status.busy": "2025-03-28T01:49:30.405826Z",
     "iopub.status.idle": "2025-03-28T01:49:31.388067Z",
     "shell.execute_reply": "2025-03-28T01:49:31.386584Z",
     "shell.execute_reply.started": "2025-03-28T01:49:30.406197Z"
    },
    "id": "uuj_oTIZabDV",
    "outputId": "c0fec4f3-4492-4608-a54f-48d800b04ba7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig1 = go.Figure()\n",
    "\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=[np.sqrt(p[\"variance\"]) for p in all_portfolios],\n",
    "    y=[p[\"return\"] for p in all_portfolios],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[p[\"sharpe\"] for p in all_portfolios],\n",
    "        showscale=True,\n",
    "        size=7,\n",
    "        line=dict(width=1),\n",
    "        colorscale=\"RdBu\",\n",
    "        colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "    ),\n",
    "    hoverinfo='text',\n",
    "    text=[\n",
    "        f\"Return: {p['return']:.3%}<br>Volatility: {np.sqrt(p['variance']):.3f}<br>\" +\n",
    "        f\"Sharpe Ratio: {p['return'] / (np.sqrt(p['variance'])):.3f}<br>\" +\n",
    "        \"<br>\".join([f\"{p['tickers'][i]}: Weight={p['weights'][i]:.3f}\" for i in range(len(p['tickers']))])\n",
    "        for p in all_portfolios\n",
    "    ]\n",
    "))\n",
    "\n",
    "fig1.update_layout(\n",
    "    xaxis=dict(title='Volatility (Standard Deviation)'),\n",
    "    yaxis=dict(title='Annualised Returns'),\n",
    "    title='Monte Carlo Randomly Generated Portfolios',\n",
    "    height=1080,\n",
    "    width=1920,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "fig1.show()\n",
    "#fig1.write_html(\"MonteCarlo.html\")\n",
    "#fig1.write_image(\"MonteCarlo.png\", format='png', width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T01:49:31.390227Z",
     "iopub.status.busy": "2025-03-28T01:49:31.389701Z",
     "iopub.status.idle": "2025-03-28T01:49:31.429758Z",
     "shell.execute_reply": "2025-03-28T01:49:31.428601Z",
     "shell.execute_reply.started": "2025-03-28T01:49:31.390178Z"
    },
    "id": "uHkH6APvabDV",
    "outputId": "8dbda4b6-b409-48de-98ea-c89f8e6f5f85",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig2 = go.Figure()\n",
    "\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=[np.sqrt(p[\"variance\"]) for p in dominant_portfolios],  # Convert variance to volatility\n",
    "    y=[p[\"return\"] for p in dominant_portfolios],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=7,\n",
    "        line=dict(width=1),\n",
    "        #showscale=True,\n",
    "        #color=[p[\"return\"] / (np.sqrt(p[\"variance\"])) for p in dominant_portfolios],  # Sharpe Ratio\n",
    "        #colorscale=\"RdBu\",\n",
    "        #colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "    ),\n",
    "    hoverinfo='text',\n",
    "    text=[\n",
    "        f\"Return: {p['return']:.3%}<br>Volatility: {np.sqrt(p['variance']):.3f}<br>\" +\n",
    "        f\"Sharpe Ratio: {p['sharpe']:.3f}<br>\" +\n",
    "        \"<br>\".join([f\"{p['tickers'][i]}: Weight={p['weights'][i]:.3f}\" for i in range(len(p['tickers']))])\n",
    "        for p in dominant_portfolios\n",
    "    ],\n",
    "    name=\"Monte Carlo Portfolios\"\n",
    "))\n",
    "\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=volatility,\n",
    "    y=annualized_returns,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    hovertext=[\n",
    "        f\"{name} <br>Volatility: {vol:.3f} <br>Returns: {ret:.3%} <br>Sharpe Ratio: {sr:.3f}\"\n",
    "        for name, vol, ret, sr in zip(names, volatility, annualized_returns, sharpe_ratios)\n",
    "    ],\n",
    "    marker=dict(\n",
    "        color='green',\n",
    "        size=5,\n",
    "        line=dict(width=1)\n",
    "    ),\n",
    "    name=\"Individual Assets\"\n",
    "))\n",
    "\n",
    "fig2.update_layout(\n",
    "    title='Monte Carlo Portfolios with Individual Assets',\n",
    "    xaxis_title='Volatility (Standard Deviation)',\n",
    "    yaxis_title='Annualized Return',\n",
    "    legend=dict(y=5),\n",
    "    height=1080,\n",
    "    width=1920,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig2.show()\n",
    "#fig2.write_html(\"MCMarkowitzBullet.html\")\n",
    "#fig2.write_image(\"MCMarkowitzBullet.png\", format='png', width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-WDtJTgabDV"
   },
   "source": [
    "## 5.0 Machine Learning Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Optimization Function Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T01:49:31.431397Z",
     "iopub.status.busy": "2025-03-28T01:49:31.431082Z",
     "iopub.status.idle": "2025-03-28T01:50:02.278310Z",
     "shell.execute_reply": "2025-03-28T01:50:02.277108Z",
     "shell.execute_reply.started": "2025-03-28T01:49:31.431361Z"
    },
    "id": "7xbdm-4NabDV",
    "outputId": "53c0d514-7544-4e8f-9ed5-4af9aa786a56",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_portfolio, best_portfolio, good_portfolios, total_portfolios, best_iteration = MLRBA_V1(names, cov, annualized_returns)\n",
    "base_portfolio, best_portfolio, len(good_portfolios), len(total_portfolios), best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T01:50:02.279927Z",
     "iopub.status.busy": "2025-03-28T01:50:02.279429Z",
     "iopub.status.idle": "2025-03-28T01:50:02.324483Z",
     "shell.execute_reply": "2025-03-28T01:50:02.323188Z",
     "shell.execute_reply.started": "2025-03-28T01:50:02.279893Z"
    },
    "id": "Znh8vrYQabDW",
    "outputId": "f770bd56-eace-405c-a8c0-a1d835201f64",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[p[\"variance\"]**0.5 for p in good_portfolios],  # Convert variance to volatility\n",
    "    y=[p[\"return\"] for p in good_portfolios],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[p[\"sharpe\"] for p in good_portfolios],  # Sharpe Ratio\n",
    "        showscale=True,\n",
    "        size=7,\n",
    "        line=dict(width=1),\n",
    "        colorscale=\"RdBu\",\n",
    "        colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "    ),\n",
    "    hoverinfo='text',\n",
    "    text=[\n",
    "        f\"Return: {p['return']:.3%}<br>Volatility: {p['variance']**0.5:.3f}<br>\" +\n",
    "        f\"Sharpe Ratio: {p['return'] / (p['variance']**0.5):.3f}<br>\" +\n",
    "        \"<br>\".join([f\"{p['tickers'][i]}: Weight={p['weights'][i]:.3f}\" for i in range(len(p['tickers']))])\n",
    "        for p in good_portfolios\n",
    "    ],\n",
    "    name=\"Portfolios\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Convergence Strategy Generarted Portfolios',\n",
    "    xaxis_title='Volatility (Standard Deviation)',\n",
    "    yaxis_title='Annualized Return',\n",
    "    legend=dict(y=5),\n",
    "    width=1920,\n",
    "    height=1080,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "#fig.write_html(\"ConvergenceRBA.html\")\n",
    "#fig.write_image(\"ConvergenceRBA.png\", format='png', width=1920, height=1080)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=volatility,\n",
    "    y=annualized_returns,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    hovertext=[\n",
    "        f\"{name} <br>Volatility: {vol:.3f} <br>Returns: {ret:.3%} <br>Sharpe Ratio: {sr:.3f}\"\n",
    "        for name, vol, ret, sr in zip(names, volatility, annualized_returns, sharpe_ratios)\n",
    "    ],\n",
    "    marker=dict(\n",
    "        color='green',\n",
    "        size=5,\n",
    "        line=dict(width=1)\n",
    "    ),\n",
    "    name=\"Individual Assets\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Convergence Strategy Generarted Portfolios with Individual Assets',\n",
    "    xaxis_title='Volatility (Standard Deviation)',\n",
    "    yaxis_title='Annualized Return',\n",
    "    legend=dict(y=5),\n",
    "    width=1920,\n",
    "    height=1080,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "#fig.write_html(\"ConvergenceRBA+Asset.html\")\n",
    "#fig.write_image(\"ConvergenceRBA+Asset.png\", format='png', width=1920, height=1080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T01:50:02.326535Z",
     "iopub.status.busy": "2025-03-28T01:50:02.326077Z",
     "iopub.status.idle": "2025-03-28T01:50:02.370036Z",
     "shell.execute_reply": "2025-03-28T01:50:02.368463Z",
     "shell.execute_reply.started": "2025-03-28T01:50:02.326487Z"
    },
    "id": "fcrLEvL3abDW",
    "outputId": "7123cd39-a752-4640-be20-6fe3fcbc6c17",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sharpe_ratios = [portfolio['sharpe'] for portfolio in total_portfolios]\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=list(range(len(sharpe_ratios))), y=sharpe_ratios, mode='lines+markers'))\n",
    "fig.update_layout(title='Sharpe Ratio Over Iterations',\n",
    "                xaxis_title='Iteration',\n",
    "                yaxis_title='Sharpe Ratio',\n",
    "                width=1920,\n",
    "                height=1080,\n",
    "                font=dict(\n",
    "                    family=\"Cambria\",\n",
    "                    size=18,\n",
    "                )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing MLRBA_V1 with Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:50:02.371193Z",
     "iopub.status.busy": "2025-03-28T01:50:02.370887Z",
     "iopub.status.idle": "2025-03-28T01:50:03.976070Z",
     "shell.execute_reply": "2025-03-28T01:50:03.974940Z",
     "shell.execute_reply.started": "2025-03-28T01:50:02.371167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "figC = go.Figure(fig2)\n",
    "figC.add_trace(go.Scatter(\n",
    "    x=[p[\"variance\"]**0.5 for p in good_portfolios],  # Convert variance to volatility\n",
    "    y=[p[\"return\"] for p in good_portfolios],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=7,\n",
    "        line=dict(width=1),\n",
    "        color=\"Red\",\n",
    "    ),\n",
    "    hoverinfo='text',\n",
    "    text=[\n",
    "        f\"Return: {p['return']:.3%}<br>Volatility: {p['variance']**0.5:.3f}<br>\" +\n",
    "        f\"Sharpe Ratio: {p['return'] / (p['variance']**0.5):.3f}<br>\" +\n",
    "        \"<br>\".join([f\"{p['tickers'][i]}: Weight={p['weights'][i]:.3f}\" for i in range(len(p['tickers']))])\n",
    "        for p in good_portfolios\n",
    "    ],\n",
    "    name=\"Convergence Portfolios\"\n",
    "))\n",
    "\n",
    "figC.update_layout(\n",
    "    title='Convergence vs Monte Carlo vs Individual Assets',\n",
    "    legend=dict(x=0.85, y=0.95),\n",
    "    width=1920,\n",
    "    height=1080,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "\n",
    "figC.show()\n",
    "#figC.write_html(\"ComparisonOfConvergence+MC.html\")\n",
    "#figC.write_image(\"ComparisonOfConvergence+MC.png\", format='png', width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Reinforcement Weight Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:50:03.977877Z",
     "iopub.status.busy": "2025-03-28T01:50:03.977357Z",
     "iopub.status.idle": "2025-03-28T01:50:11.560961Z",
     "shell.execute_reply": "2025-03-28T01:50:11.559727Z",
     "shell.execute_reply.started": "2025-03-28T01:50:03.977831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_portfolio, best_portfolio, good_portfolios, total_portfolios, best_iteration = MLRBA_V2(names, cov, annualized_returns, correlation_matrix)\n",
    "base_portfolio, best_portfolio, len(good_portfolios), len(total_portfolios), best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:50:11.562544Z",
     "iopub.status.busy": "2025-03-28T01:50:11.562152Z",
     "iopub.status.idle": "2025-03-28T01:50:11.602498Z",
     "shell.execute_reply": "2025-03-28T01:50:11.600912Z",
     "shell.execute_reply.started": "2025-03-28T01:50:11.562508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[p[\"variance\"]**0.5 for p in good_portfolios],  # Convert variance to volatility\n",
    "    y=[p[\"return\"] for p in good_portfolios],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[p[\"sharpe\"] for p in good_portfolios],  # Sharpe Ratio\n",
    "        showscale=True,\n",
    "        size=7,\n",
    "        line=dict(width=1),\n",
    "        colorscale=\"RdBu\",\n",
    "        colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "    ),\n",
    "    hoverinfo='text',\n",
    "    text=[\n",
    "        f\"Return: {p['return']:.3%}<br>Volatility: {p['variance']**0.5:.3f}<br>\" +\n",
    "        f\"Sharpe Ratio: {p['return'] / (p['variance']**0.5):.3f}<br>\" +\n",
    "        \"<br>\".join([f\"{p['tickers'][i]}: Weight={p['weights'][i]:.3f}\" for i in range(len(p['tickers']))])\n",
    "        for p in good_portfolios\n",
    "    ],\n",
    "    name=\"Portfolios\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Learning Convergence Portfolios',\n",
    "    xaxis_title='Volatility (Standard Deviation)',\n",
    "    yaxis_title='Annualized Return',\n",
    "    legend=dict(y=5),\n",
    "    width=1920,\n",
    "    height=1080,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "#fig.write_html(\"LearningConvergenceRBA.html\")\n",
    "#fig.write_image(\"LearningConvergenceRBA.png\", format='png', width=1920, height=1080)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=volatility,\n",
    "    y=annualized_returns,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    hovertext=[\n",
    "        f\"{name} <br>Volatility: {vol:.3f} <br>Returns: {ret:.3%} <br>Sharpe Ratio: {sr:.3f}\"\n",
    "        for name, vol, ret, sr in zip(names, volatility, annualized_returns, sharpe_ratios)\n",
    "    ],\n",
    "    marker=dict(\n",
    "        color='green',\n",
    "        size=5,\n",
    "        line=dict(width=1)\n",
    "    ),\n",
    "    name=\"Individual Assets\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Learning Convergence Portfolios with Individual Assets',\n",
    "    xaxis_title='Volatility (Standard Deviation)',\n",
    "    yaxis_title='Annualized Return',\n",
    "    legend=dict(y=5),\n",
    "    width=1920,\n",
    "    height=1080,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "#fig.write_html(\"LearningConvergenceRBA+Asset.html\")\n",
    "#fig.write_image(\"LearningConvergenceRBA+Asset.png\", format='png', width=1920, height=1080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:50:11.604457Z",
     "iopub.status.busy": "2025-03-28T01:50:11.604098Z",
     "iopub.status.idle": "2025-03-28T01:50:11.625195Z",
     "shell.execute_reply": "2025-03-28T01:50:11.623946Z",
     "shell.execute_reply.started": "2025-03-28T01:50:11.604415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sharpe_ratios = [portfolio['sharpe'] for portfolio in total_portfolios]\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=list(range(len(sharpe_ratios))), y=sharpe_ratios, mode='lines+markers'))\n",
    "fig.update_layout(title='Sharpe Ratio Over Iterations',\n",
    "                  xaxis_title='Iteration',\n",
    "                  yaxis_title='Sharpe Ratio',\n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing MLRBA_V2 with Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:50:11.626994Z",
     "iopub.status.busy": "2025-03-28T01:50:11.626392Z",
     "iopub.status.idle": "2025-03-28T01:50:11.679095Z",
     "shell.execute_reply": "2025-03-28T01:50:11.677715Z",
     "shell.execute_reply.started": "2025-03-28T01:50:11.626958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "figC = go.Figure(fig2)\n",
    "figC.add_trace(go.Scatter(\n",
    "    x=[p[\"variance\"]**0.5 for p in good_portfolios],  # Convert variance to volatility\n",
    "    y=[p[\"return\"] for p in good_portfolios],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=7,\n",
    "        line=dict(width=1),\n",
    "        color=\"Red\",\n",
    "    ),\n",
    "    hoverinfo='text',\n",
    "    text=[\n",
    "        f\"Return: {p['return']:.3%}<br>Volatility: {p['variance']**0.5:.3f}<br>\" +\n",
    "        f\"Sharpe Ratio: {p['return'] / (p['variance']**0.5):.3f}<br>\" +\n",
    "        \"<br>\".join([f\"{p['tickers'][i]}: Weight={p['weights'][i]:.3f}\" for i in range(len(p['tickers']))])\n",
    "        for p in good_portfolios\n",
    "    ],\n",
    "    name=\"Learning Convergence Portfolios\"\n",
    "))\n",
    "\n",
    "figC.update_layout(\n",
    "    title='Learning Convergence vs Monte Carlo vs Individual Assets',\n",
    "    legend=dict(x=0.8, y=0.95),\n",
    "    width=1920,\n",
    "    height=1080,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "\n",
    "figC.show()\n",
    "#figC.write_html(\"ComparisonOfLearningConvergence+MC.html\")\n",
    "#figC.write_image(\"ComparisonOfLearningConvergence+MC.png\", format='png', width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing V1 and V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:50:11.680512Z",
     "iopub.status.busy": "2025-03-28T01:50:11.680086Z",
     "iopub.status.idle": "2025-03-28T01:58:45.374167Z",
     "shell.execute_reply": "2025-03-28T01:58:45.371622Z",
     "shell.execute_reply.started": "2025-03-28T01:50:11.680469Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_MLRBA_multiple_times(names, cov, annualized_returns, num_runs, num_assets=8):\n",
    "\n",
    "    def generate_rand_port(tickers, num_assets, num_runs):\n",
    "        rand_port = []\n",
    "        for _ in range (num_runs):\n",
    "            base_portfolio = np.random.choice(list(tickers), num_assets, replace=False)\n",
    "            rand_port.append(base_portfolio)\n",
    "\n",
    "        return rand_port\n",
    "    \n",
    "    random_portfolios = generate_rand_port(names, num_assets=num_assets, num_runs=num_runs)\n",
    "\n",
    "    total_good_portfolios_length_v1 = 0\n",
    "    best_portfolios_v1 = []\n",
    "    best_iterations_v1 = []\n",
    "    \n",
    "    total_good_portfolios_length_v2 = 0\n",
    "    best_portfolios_v2 = []\n",
    "    best_iterations_v2 = []\n",
    "    \n",
    "    for portfolio in random_portfolios:\n",
    "        base_portfolio_v1, best_portfolio_v1, good_portfolios_v1, _, best_iteration_v1 = MLRBA_V1(names, cov, annualized_returns, base_portfolio=portfolio)\n",
    "        total_good_portfolios_length_v1 += len(good_portfolios_v1)\n",
    "        best_portfolios_v1.append(best_portfolio_v1)\n",
    "        best_iterations_v1.append(best_iteration_v1)\n",
    "        \n",
    "        base_portfolio_v2, best_portfolio_v2, good_portfolios_v2, _, best_iteration_v2 = MLRBA_V2(names, cov, annualized_returns, correlation_matrix, base_portfolio=portfolio)\n",
    "        total_good_portfolios_length_v2 += len(good_portfolios_v2)\n",
    "        best_portfolios_v2.append(best_portfolio_v2)\n",
    "        best_iterations_v2.append(best_iteration_v2)\n",
    "\n",
    "        print(base_portfolio_v1['tickers'] == base_portfolio_v2['tickers'])\n",
    "\n",
    "    average_length_v1 = total_good_portfolios_length_v1 / num_runs\n",
    "    average_iteration_v1 = statistics.fmean(best_iterations_v1)\n",
    "    std_dev_iteration_v1 = statistics.stdev(best_iterations_v1) if num_runs > 1 else 0\n",
    "\n",
    "    average_length_v2 = total_good_portfolios_length_v2 / num_runs\n",
    "    average_iteration_v2 = statistics.fmean(best_iterations_v2)\n",
    "    std_dev_iteration_v2 = statistics.stdev(best_iterations_v2) if num_runs > 1 else 0\n",
    "\n",
    "    \n",
    "    results = {\n",
    "        'v1': (base_portfolio_v1, average_length_v1, best_portfolios_v1, average_iteration_v1, std_dev_iteration_v1, best_iterations_v1),\n",
    "        'v2': (base_portfolio_v2, average_length_v2, best_portfolios_v2, average_iteration_v2, std_dev_iteration_v2, best_iterations_v2)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "num_runs = 20\n",
    "results = run_MLRBA_multiple_times(names, cov, annualized_returns, num_runs)\n",
    "\n",
    "_, _, best_portfolios_v1, average_iteration_v1, std_dev_v1, best_iterations_v1 = results['v1']\n",
    "_, _, best_portfolios_v2, average_iteration_v2, std_dev_v2, best_iterations_v2 = results['v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:58:45.375415Z",
     "iopub.status.busy": "2025-03-28T01:58:45.375113Z",
     "iopub.status.idle": "2025-03-28T01:58:45.436100Z",
     "shell.execute_reply": "2025-03-28T01:58:45.434935Z",
     "shell.execute_reply.started": "2025-03-28T01:58:45.375380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "avg_sharpe_v1 = np.mean([portfolio['sharpe'] for portfolio in best_portfolios_v1])\n",
    "avg_sharpe_v2 = np.mean([portfolio['sharpe'] for portfolio in best_portfolios_v2])\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=[\n",
    "        \"Average Iterations to Find Best Portfolio\",\n",
    "        \"Average Highest Sharpe Ratio\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=['Standard Convergence', 'Learning Convergergence'],\n",
    "    y=[average_iteration_v1, average_iteration_v2],\n",
    "    name='Iterations',\n",
    "    error_y=dict(type='data', array=[std_dev_v1, std_dev_v2], visible=True),\n",
    "    width=0.4\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=['Standard Convergence', 'Learning Convergergence'],\n",
    "    y=[avg_sharpe_v1, avg_sharpe_v2],\n",
    "    name='Sharpe Ratio',\n",
    "    width=0.4\n",
    "), row=1, col=2)\n",
    "\n",
    "# Axis titles\n",
    "fig.update_xaxes(title_text='Method Version', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Average Iterations', row=1, col=1)\n",
    "\n",
    "fig.update_xaxes(title_text='Method Version', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Average Sharpe Ratio', row=1, col=2)\n",
    "\n",
    "# Layout and display\n",
    "fig.update_layout(\n",
    "    title_text='Standard Convergence vs Learning Convergence',\n",
    "    showlegend=False,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "#fig.write_html(\"StandardvsLearning.html\")\n",
    "#fig.write_image(\"StandardvsLearning.png\", format='png', width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Portfolio Prediction using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:58:45.441291Z",
     "iopub.status.busy": "2025-03-28T01:58:45.440926Z",
     "iopub.status.idle": "2025-03-28T01:58:45.463114Z",
     "shell.execute_reply": "2025-03-28T01:58:45.461656Z",
     "shell.execute_reply.started": "2025-03-28T01:58:45.441259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PortfolioPredictor:\n",
    "    def __init__(self, raw_data_train, raw_data_test, best_portfolio, n_steps=1, epochs=50, batch_size=32):\n",
    "        self.raw_data_train = raw_data_train\n",
    "        self.raw_data_test = raw_data_test\n",
    "        self.best_portfolio = best_portfolio\n",
    "        self.n_steps = n_steps\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        best_portfolio_data_train = self.raw_data_train[self.best_portfolio['tickers']]\n",
    "        best_portfolio_data_test = self.raw_data_test[self.best_portfolio['tickers']]\n",
    "        weights = np.array(self.best_portfolio['weights'])\n",
    "\n",
    "        # Use a scaler fitted on a broader dataset so that training/test normalization is consistent\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        # Fit on the entire raw_data (or on a fixed training period) for consistency\n",
    "        full_data = pd.concat([best_portfolio_data_train, best_portfolio_data_test])\n",
    "        self.scaler.fit(full_data)\n",
    "        \n",
    "        normalized_train_data = self.scaler.transform(best_portfolio_data_train)\n",
    "        normalized_test_data = self.scaler.transform(best_portfolio_data_test)\n",
    "\n",
    "        self.weighted_returns_train = np.dot(normalized_train_data, weights)\n",
    "        self.weighted_returns_test = np.dot(normalized_test_data, weights)\n",
    "\n",
    "    def create_datasets(self, data):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - self.n_steps):\n",
    "            v = data[i:(i + self.n_steps), :]\n",
    "            X.append(v)\n",
    "            y.append(data[i + self.n_steps, :])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model = Sequential([\n",
    "            LSTM(250, activation='tanh', return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(50, activation='tanh', return_sequences=False),\n",
    "            Dropout(0.2),\n",
    "            Dense(1),\n",
    "        ])\n",
    "\n",
    "        def tf_weighted_mse(y_true, y_pred, power=3):\n",
    "            n = tf.shape(y_true)[0]\n",
    "            normalized_index = tf.cond(\n",
    "                tf.equal(n, 1),\n",
    "                lambda: tf.ones([n], dtype=tf.float32),\n",
    "                lambda: tf.cast(tf.range(n), tf.float32) / tf.cast(n - 1, tf.float32)\n",
    "            )\n",
    "            weights = tf.pow(normalized_index, power)\n",
    "            weights += 1e-6\n",
    "            weights /= tf.reduce_sum(weights)\n",
    "            \n",
    "            squared_errors = tf.square(y_true - y_pred)\n",
    "            weighted_squared_errors = weights * squared_errors\n",
    "            return tf.reduce_mean(weighted_squared_errors)\n",
    "\n",
    "        self.model.compile(optimizer='adam', loss=tf_weighted_mse)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.X_train_weighted, self.y_train_weighted = self.create_datasets(self.weighted_returns_train.reshape(-1, 1))\n",
    "        self.history = self.model.fit(self.X_train_weighted, self.y_train_weighted, epochs=self.epochs, batch_size=self.batch_size, validation_split=0.001, shuffle=False, verbose=0)\n",
    "\n",
    "    def predict(self):\n",
    "        X_test_weighted, y_test_weighted = self.create_datasets(self.weighted_returns_test.reshape(-1, 1))\n",
    "        \n",
    "        self.predictions = self.model.predict(X_test_weighted)\n",
    "        self.y_test_weighted = y_test_weighted\n",
    "        \n",
    "        return self.predictions\n",
    "\n",
    "    def compute_cumulative_returns(self, data, baseline):\n",
    "        data_series = pd.Series(data.flatten())\n",
    "        cumulative_returns = data_series / data_series.iloc[0] * baseline\n",
    "        return cumulative_returns\n",
    "\n",
    "    def plot_loss(self):\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=np.arange(1, len(self.history.history['loss'])+1), y=self.history.history['loss'], mode='lines', name='Training Loss'))\n",
    "        fig.add_trace(go.Scatter(x=np.arange(1, len(self.history.history['val_loss'])+1), y=self.history.history['val_loss'], mode='lines', name='Validation Loss'))\n",
    "        fig.update_layout(title='Training and Validation Loss Over Epochs',\n",
    "                            xaxis_title='Epoch',\n",
    "                            yaxis_title='Loss',\n",
    "                            legend_title='Type of Loss',\n",
    "                            width=1920,\n",
    "                            height=1080,\n",
    "                            font=dict(\n",
    "                                family=\"Cambria\",\n",
    "                                size=18,\n",
    "                            ))\n",
    "        fig.show()\n",
    "        \n",
    "    def plot_predictions(self):\n",
    "        normalized_train = self.compute_cumulative_returns(self.y_train_weighted, 100)\n",
    "        training_end_value = normalized_train.iloc[-1]\n",
    "        normalized_test = self.compute_cumulative_returns(self.y_test_weighted, training_end_value)\n",
    "        normalized_predicted = self.compute_cumulative_returns(self.predictions, training_end_value)\n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=self.raw_data_train.index,\n",
    "            y=normalized_train,\n",
    "            mode='lines',\n",
    "            name='Actual Training Returns'\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=self.raw_data_test.index,\n",
    "            y=normalized_test,\n",
    "            mode='lines',\n",
    "            name='Actual Test Returns'\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=self.raw_data_test.index,\n",
    "            y=normalized_predicted,\n",
    "            mode='lines',\n",
    "            name='Predicted Test Returns'\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title='Actual vs Predicted Weighted Portfolio Returns',\n",
    "            xaxis_title='Date',\n",
    "            yaxis_title='Cumulative Returns',\n",
    "            legend_title='Portfolio',\n",
    "            width=1920,\n",
    "            height=1080,\n",
    "            font=dict(\n",
    "                family=\"Cambria\",\n",
    "                size=18,\n",
    "            )\n",
    "        )\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T01:58:45.465266Z",
     "iopub.status.busy": "2025-03-28T01:58:45.464960Z",
     "iopub.status.idle": "2025-03-28T02:00:26.052539Z",
     "shell.execute_reply": "2025-03-28T02:00:26.051044Z",
     "shell.execute_reply.started": "2025-03-28T01:58:45.465239Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "investment_length = 90\n",
    "investment_end_date = end_date + pd.Timedelta(days=investment_length)\n",
    "\n",
    "raw_data, asset_errors, max_combination= fetch_raw_data_yf(assets, start_date, investment_end_date)\n",
    "names, annualized_returns, unweighted_annaulized_returns, weighted_returns_matrix, normal_returns_matrix, cov, correlation_matrix = get_matrices(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_train = raw_data.loc[:end_date]\n",
    "raw_data_test = raw_data.loc[end_date:]\n",
    "\n",
    "portfolio_predictor = PortfolioPredictor(raw_data_train, raw_data_test, best_portfolio, n_steps=1, epochs=30)\n",
    "\n",
    "portfolio_predictor.preprocess_data()\n",
    "portfolio_predictor.build_model()\n",
    "portfolio_predictor.train_model()\n",
    "prediction = portfolio_predictor.predict()   \n",
    "portfolio_predictor.plot_loss()\n",
    "portfolio_predictor.plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T02:00:26.054061Z",
     "iopub.status.busy": "2025-03-28T02:00:26.053732Z",
     "iopub.status.idle": "2025-03-28T02:00:26.067770Z",
     "shell.execute_reply": "2025-03-28T02:00:26.066463Z",
     "shell.execute_reply.started": "2025-03-28T02:00:26.054033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_portfolios_over_time(raw_data, window_size=5, threshold=0.05, epochs=30, length_of_investment = None):\n",
    "    investment_start = len(raw_data[:end_date])\n",
    "\n",
    "    trading_days = len(raw_data[end_date:end_date + pd.Timedelta(days=length_of_investment)] if length_of_investment is not None else raw_data[end_date:])\n",
    "    trading_days = trading_days - 1 if trading_days % window_size == 0 else trading_days\n",
    "    num_windows = trading_days // window_size\n",
    "\n",
    "    previous_best_portfolio = None\n",
    "    all_good_portfolios = []\n",
    "    for i in range(num_windows):\n",
    "        print(f'Predicting Week {i} in {num_windows} Total Weeks')\n",
    "\n",
    "        loop_raw_data_train = raw_data.iloc[:investment_start + i*window_size]\n",
    "        loop_raw_data_test = raw_data.iloc[investment_start + i*window_size:]\n",
    "        \n",
    "        loop_names, loop_annualized_returns, _, _, _, loop_cov, loop_correlation_matrix = get_matrices(loop_raw_data_train)\n",
    "        \n",
    "        _, loop_best_portfolio, loop_good_portfolios, _, _ = MLRBA_V2(loop_names, loop_cov, loop_annualized_returns, loop_correlation_matrix)\n",
    "        best_sharpe = loop_best_portfolio['sharpe']\n",
    "        \n",
    "        close_to_best = []\n",
    "        if previous_best_portfolio is not None:\n",
    "            close_to_best.append(previous_best_portfolio)\n",
    "        close_to_best.append(loop_best_portfolio)\n",
    "        \n",
    "        for j in range(len(loop_best_portfolio)):\n",
    "            difference = abs((best_sharpe - loop_good_portfolios[j]['sharpe']) / best_sharpe)\n",
    "            if difference < threshold:\n",
    "                close_to_best.append(loop_good_portfolios[j])\n",
    "\n",
    "        print(f'Length of close to best is: {len(close_to_best)}')\n",
    "\n",
    "        sharpe_list = [portfolio['sharpe'] for portfolio in close_to_best]\n",
    "        print(\"Sharpe ratios (first is best_sharpe):\", sharpe_list)\n",
    "        \n",
    "        portfolio_results = {}\n",
    "        for id, portfolio in enumerate(close_to_best):\n",
    "            portfolio_predictor = PortfolioPredictor(loop_raw_data_train, loop_raw_data_test, portfolio, n_steps=window_size, epochs=epochs)\n",
    "            portfolio_predictor.preprocess_data()\n",
    "            portfolio_predictor.build_model()\n",
    "            portfolio_predictor.train_model()\n",
    "            prediction = portfolio_predictor.predict() \n",
    "\n",
    "            if len(prediction) >= window_size:\n",
    "                end_pred = prediction[window_size-1]\n",
    "            else:\n",
    "                end_pred = prediction[-1]\n",
    "            \n",
    "            percentage_diff = (end_pred - prediction[0]) / prediction[0]\n",
    "            print(prediction[:min(window_size, len(prediction))], prediction[0], percentage_diff * 100)          \n",
    "            \n",
    "            portfolio_results[id] = percentage_diff\n",
    "\n",
    "        best_id = None\n",
    "\n",
    "        # Check if all predictions (percentage_diff) are negative\n",
    "        if max(portfolio_results.values()) < 0:\n",
    "            print(\"All percentage differences are negative. Choosing an empty portfolio(not holding anything).\")\n",
    "            predicted_best_portfolio = {}\n",
    "        else:\n",
    "            best_id = max(portfolio_results, key=portfolio_results.get)\n",
    "            predicted_best_portfolio = close_to_best[best_id]\n",
    "            previous_best_portfolio = predicted_best_portfolio\n",
    "        \n",
    "        portfolio_start_date = loop_raw_data_test.index[0]\n",
    "        portfolio_end_date = loop_raw_data_test.index[window_size-1]\n",
    "        \n",
    "        all_good_portfolios.append({\n",
    "            \"portfolio\": predicted_best_portfolio,\n",
    "            \"start_date\": portfolio_start_date,\n",
    "            \"end_date\": portfolio_end_date\n",
    "        })\n",
    "        if best_id is not None:\n",
    "            print(f'Current iteration: {i}, the best portfolio found was portfolio: {best_id}')\n",
    "        else:\n",
    "            print(f'Current iteration: {i}, no portfolio selected (empty portfolio chosen).')\n",
    "    \n",
    "    return all_good_portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T02:00:26.069547Z",
     "iopub.status.busy": "2025-03-28T02:00:26.069021Z",
     "iopub.status.idle": "2025-03-28T04:29:52.544768Z",
     "shell.execute_reply": "2025-03-28T04:29:52.543289Z",
     "shell.execute_reply.started": "2025-03-28T02:00:26.069496Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_good_portfolios = evaluate_portfolios_over_time(raw_data, window_size=5, threshold=0.5, epochs=20, length_of_investment = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T04:29:52.555427Z",
     "iopub.status.busy": "2025-03-28T04:29:52.555028Z",
     "iopub.status.idle": "2025-03-28T04:29:52.817373Z",
     "shell.execute_reply": "2025-03-28T04:29:52.816414Z",
     "shell.execute_reply.started": "2025-03-28T04:29:52.555397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_asset_returns(raw_data, assets, start_date, end_date):\n",
    "    if not isinstance(raw_data.index, pd.DatetimeIndex):\n",
    "        raw_data.index = pd.to_datetime(raw_data.index)\n",
    "\n",
    "    filtered_data = raw_data.loc[start_date:end_date, assets]\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def chain_portfolio_performance(weekly_series_list, starting_value=100):\n",
    "    continuous_series = pd.Series()\n",
    "    current_value = starting_value\n",
    "\n",
    "    for week_series in weekly_series_list:\n",
    "        # Normalize the week so that it starts at 1 (or current_value)\n",
    "        week_normalized = week_series / week_series.iloc[0]\n",
    "        # Scale the normalized week to start at current_value\n",
    "        week_scaled = week_normalized * current_value\n",
    "        # Update the current_value to the last value of this week\n",
    "        current_value = week_scaled.iloc[-1]\n",
    "        # Append the week_series to the continuous_series\n",
    "        continuous_series = pd.concat([continuous_series, week_scaled])\n",
    "    \n",
    "    return continuous_series\n",
    "\n",
    "ML_portfolio = []\n",
    "portfolio_holdings = []  # To store tickers held at each point\n",
    "initial_value = 100\n",
    "\n",
    "for i in range(len(all_good_portfolios)):\n",
    "    curr_best_portfolio = all_good_portfolios[i]['portfolio']\n",
    "    p_start_date = all_good_portfolios[i]['start_date']\n",
    "    p_end_date = all_good_portfolios[i]['end_date']\n",
    "    \n",
    "    if not curr_best_portfolio:\n",
    "        # No portfolio for this period\n",
    "        if i == 0:\n",
    "            previous_value = initial_value\n",
    "        else:\n",
    "            previous_value = ML_portfolio[-1].iloc[-1]\n",
    "        window_index = raw_data.loc[p_start_date:p_end_date].index\n",
    "        portfolio_daily_returns = pd.Series(previous_value, index=window_index)\n",
    "        held_tickers = []  # Nothing held\n",
    "    else:\n",
    "        # Portfolio exists for this period\n",
    "        best_curr_port_assets = curr_best_portfolio['tickers']\n",
    "        best_curr_port_assets_test_data = extract_asset_returns(raw_data, best_curr_port_assets, p_start_date, p_end_date)\n",
    "        curr_best_portfolio_weights = curr_best_portfolio['weights']\n",
    "        weighted_returns = best_curr_port_assets_test_data.mul(curr_best_portfolio_weights, axis='columns')\n",
    "        portfolio_daily_returns = weighted_returns.sum(axis=1)\n",
    "        held_tickers = best_curr_port_assets\n",
    "\n",
    "    ML_portfolio.append(portfolio_daily_returns)\n",
    "    portfolio_holdings.append((p_start_date, p_end_date, held_tickers))\n",
    "\n",
    "ML_portfolio_streamed = chain_portfolio_performance(ML_portfolio, starting_value=initial_value)\n",
    "\n",
    "# Print tickers held at each point\n",
    "for period_info in portfolio_holdings:\n",
    "    start, end, tickers = period_info\n",
    "    print(f\"Held from {start} to {end}: {tickers}\")\n",
    "\n",
    "ML_portfolio_streamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T04:52:43.019676Z",
     "iopub.status.busy": "2025-03-28T04:52:43.019281Z",
     "iopub.status.idle": "2025-03-28T04:52:43.157616Z",
     "shell.execute_reply": "2025-03-28T04:52:43.156279Z",
     "shell.execute_reply.started": "2025-03-28T04:52:43.019644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ML_daily_returns = ML_portfolio_streamed.pct_change()\n",
    "ML_cumulative_returns = (1 + ML_daily_returns).cumprod()\n",
    "\n",
    "ML_cumulative_returns.iloc[0] = 1\n",
    "ML_portfolio_normalized = (ML_cumulative_returns / ML_cumulative_returns.iloc[0]) * 100\n",
    "\n",
    "Nasdaq_comp = getNasdaq_comp(ML_portfolio_streamed.index[0], ML_portfolio_streamed.index[-1])\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=Nasdaq_comp.index,\n",
    "    y=Nasdaq_comp['Normalized'],\n",
    "    mode='lines',\n",
    "    name='Nasdaq Composite'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=ML_cumulative_returns.index,\n",
    "    y=ML_portfolio_normalized,\n",
    "    mode='lines',\n",
    "    name='Portfolio Growth'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Comparison of Portfolio vs. Nasdaq Composite Growth',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Normalized Value (Base 100)',\n",
    "    xaxis=dict(\n",
    "        type='date',\n",
    "        tickformat='%b %Y',\n",
    "        tickmode='auto'\n",
    "    ),\n",
    "    width=1920,\n",
    "    height=1080,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "fig.show()\n",
    "#fig.write_html(\"RBAVsNasdaq.html\")\n",
    "#fig.write_image(\"RBAVsNasdaq.png\", format='png', width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5u_KAQS1CRr"
   },
   "source": [
    "## 7.0 Testing Against Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T04:52:45.753176Z",
     "iopub.status.busy": "2025-03-28T04:52:45.752653Z",
     "iopub.status.idle": "2025-03-28T04:52:45.914394Z",
     "shell.execute_reply": "2025-03-28T04:52:45.913275Z",
     "shell.execute_reply.started": "2025-03-28T04:52:45.753132Z"
    },
    "id": "n4AB0laC1CRr",
    "outputId": "4b139451-2662-435b-dc3d-56a5eed5b189",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_port_assets = best_portfolio['tickers']\n",
    "best_port_assets_test_data = raw_data_test.loc[:, best_port_assets]\n",
    "\n",
    "Nasdaq_comp = getNasdaq_comp(ML_cumulative_returns.index[0], ML_cumulative_returns.index[-1])\n",
    "\n",
    "best_portfolio_weights = best_portfolio['weights']\n",
    "normalized_prices = best_port_assets_test_data.div(best_port_assets_test_data.iloc[0])\n",
    "daily_returns = normalized_prices.pct_change()\n",
    "weighted_returns = daily_returns.mul(best_portfolio_weights, axis='columns')\n",
    "portfolio_daily_returns = weighted_returns.sum(axis=1)\n",
    "portfolio_cumulative_returns = (1 + portfolio_daily_returns).cumprod()\n",
    "\n",
    "portfolio_start = portfolio_cumulative_returns.iloc[0]\n",
    "portfolio_normalized = (portfolio_cumulative_returns / portfolio_start) * 100\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=Nasdaq_comp.index,\n",
    "    y=Nasdaq_comp['Normalized'],\n",
    "    mode='lines',\n",
    "    name='Nasdaq Composite'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=ML_cumulative_returns.index,\n",
    "    y=ML_portfolio_normalized,\n",
    "    mode='lines',\n",
    "    name='Portfolio with Adjustments'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=ML_cumulative_returns.index,\n",
    "    y=portfolio_normalized,\n",
    "    mode='lines',\n",
    "    name='Base Portfolio'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Comparison of Portfolio vs. Nasdaq Composite Growth : 2021-2023',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Normalized Value (Base 100)',\n",
    "    xaxis=dict(\n",
    "        type='date',\n",
    "        tickformat='%b %Y',\n",
    "        tickmode='auto'\n",
    "    ),\n",
    "    width=1920,\n",
    "    height=1080,\n",
    "    font=dict(\n",
    "        family=\"Cambria\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(\"MLRBAvsRBAvsNasdaq.html\")\n",
    "fig.write_image(\"MLRBAvsRBAvsNasdaq.png\", format='png', width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 Find Optimal Portfolio Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T04:29:53.184138Z",
     "iopub.status.busy": "2025-03-28T04:29:53.183784Z",
     "iopub.status.idle": "2025-03-28T04:33:57.922788Z",
     "shell.execute_reply": "2025-03-28T04:33:57.921447Z",
     "shell.execute_reply.started": "2025-03-28T04:29:53.184109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_portfolios, dominant_portfolios = MonteCarloRBA(names, cov, annualized_returns, 10000, 'sharpe', 3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T04:33:57.926499Z",
     "iopub.status.busy": "2025-03-28T04:33:57.926159Z",
     "iopub.status.idle": "2025-03-28T04:33:57.988969Z",
     "shell.execute_reply": "2025-03-28T04:33:57.988026Z",
     "shell.execute_reply.started": "2025-03-28T04:33:57.926470Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rd_portfolio_sizes = [len(portfolio['tickers']) for portfolio in all_portfolios]\n",
    "rd_volatility = [np.sqrt(portfolio['variance']) for portfolio in all_portfolios]\n",
    "rd_returns = [portfolio['return'] for portfolio in all_portfolios]\n",
    "\n",
    "volatility_by_size = defaultdict(list)\n",
    "for size, vol, ret in zip(rd_portfolio_sizes, rd_volatility, rd_returns):\n",
    "    volatility_by_size[size].append((vol, ret))\n",
    "\n",
    "average_volatility = {size: np.mean([v[0] for v in vols]) for size, vols in volatility_by_size.items()}\n",
    "average_returns = {size: np.mean([v[1] for v in vols]) for size, vols in volatility_by_size.items()}\n",
    "\n",
    "sorted_sizes = sorted(average_volatility.keys())\n",
    "sorted_average_vols = [average_volatility[size] for size in sorted_sizes]\n",
    "sorted_average_rets = [average_returns[size] for size in sorted_sizes]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sorted_sizes,\n",
    "    y=sorted_average_vols,\n",
    "    mode='lines',\n",
    "    name='Average Volatility'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Average Volatility and Returns by Portfolio Size',\n",
    "    xaxis_title='Number of Assets in Portfolio',\n",
    "    yaxis_title='Average Value',\n",
    "    xaxis=dict(type='category'),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T04:33:57.990592Z",
     "iopub.status.busy": "2025-03-28T04:33:57.990298Z",
     "iopub.status.idle": "2025-03-28T04:44:34.066599Z",
     "shell.execute_reply": "2025-03-28T04:44:34.065198Z",
     "shell.execute_reply.started": "2025-03-28T04:33:57.990568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_portfolios, dominant_portfolios = MonteCarloRBA(names, cov, annualized_returns, 10000, 'vol', 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T04:44:34.072029Z",
     "iopub.status.busy": "2025-03-28T04:44:34.071658Z",
     "iopub.status.idle": "2025-03-28T04:44:34.271067Z",
     "shell.execute_reply": "2025-03-28T04:44:34.270020Z",
     "shell.execute_reply.started": "2025-03-28T04:44:34.071999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rd_portfolio_sizes = [sum(weight > 0 for weight in portfolio['weights']) for portfolio in all_portfolios]\n",
    "\n",
    "portfolio_size_counts = Counter(rd_portfolio_sizes)\n",
    "\n",
    "sizes = sorted(portfolio_size_counts.keys())\n",
    "counts = [portfolio_size_counts[size] for size in sizes]\n",
    "\n",
    "fig = go.Figure(data=[go.Bar(x=sizes, y=counts)])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Distribution of Portfolio Sizes After Optimization',\n",
    "    xaxis_title='Number of assets in portfolio after optimizing',\n",
    "    yaxis_title='Number of Portfolios',\n",
    "    xaxis=dict(type='category'),\n",
    "    yaxis=dict(type='linear')\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T04:44:34.272635Z",
     "iopub.status.busy": "2025-03-28T04:44:34.272240Z",
     "iopub.status.idle": "2025-03-28T04:44:34.277238Z",
     "shell.execute_reply": "2025-03-28T04:44:34.275954Z",
     "shell.execute_reply.started": "2025-03-28T04:44:34.272594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#fig.write_html(\"PortfolioSize.html\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6985997,
     "sourceId": 11190608,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "roboA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
